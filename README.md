# Challenge Hippo 
____________________

# About the coding exercise
#### GOAL 1: Read data stored in JSON files
Read pharmacy, claims and reverts from the provided files in your entry point.
Some events may not comply with the provided schema. You can use the library of your choice to perform the JSON parsing.
We are only interested in events from Pharmacy dataset.

> The solution for this exercise you can find in the `goal_one.py` file located inside of the folder `src`

#### GOAL 2: Calculate metrics for some dimensions
We want to check how some metrics perform depending on a few dimensions.
Metrics: Count of claims, Count of reverts, Average unit price, Total price
Dimensions: npi, ndc

> The solution for this exercise you can find in the `goal_two.py` file located inside of the folder `src`.

#### GOAL 3: Make a recommendation for the top 2 Chain to be displayed for each Drug.
Make a recommendation for the top 2 Chain to be displayed for each Drug.
The business team wants to understand Drug unit prices per Chain.
To measure performance, we will check the chain that, on average, charges less
per drug unit. Please, write the output to a JSON file.

> The solution for this exercise you can find in the `goal_three.py` file located inside of the folder `src`.

#### GOAL 4: Understand Most common quantity prescribed for a given Drug
Understand Most common quantity prescribed for a given Drug.
The business team wants to know what is the Drug most common quantity
prescribed to negotiate prices discounts. Please, write the output to a JSON file.

> The solution for this exercise you can find in the `goal_four.py` file located inside of the folder `src`.

# The repository's structure

```text
challenge_hippo/
├── analisys/
│ |  └── claims_table_report.html
├── database/
│ |  └── hippo.db
├── input/
│ |  └── claims/
│ |     ├── output-2f620de6-8807-47bd-8034-13eec976c826.json
│ |  └── pharmacies/
│ |     ├── output-09482089-7f1b-4d36-a21f-4652ed460166.csv
│ |  └── reverts/
│ |     ├── output-1d5d70e3-d417-4fea-970d-95c04c64e0d5.json
├── output/
│ |  ├── metrics.json
│ |  ├── most_common_quantities.json
│ |  └── top_chains.json
├── src/
│ |  ├── goal_four.py
│ |  ├── goal_one.py
│ |  ├── goal_three.py
│ |  └── goal_two.py
├── .gitignore
├── eda.py
├── hippo.py
├── LICENSE
├── README.md
├── requirements.txt
└── setup_project.sh
```

**Overview**
- The `analisys` folder contains an exploratory data analysis (EDA) report generated by the `eda.py` script, located in the project root directory.
- The `database` folder contains an olap database (DuckDB), generated by the `goal_one.py` script, located in the `src` directory.
- The `input` folder contains the CSV/JSON files. These files are derived from the compressed `data.tar.gz` file, which must be moved or copied into this folder after being uncompressed. These files are used by the `goal_one.py` script to create the database that is located in the `database` folder.
- The `output` folder contains the JSON files, which are the results of exercises 2, 3, 4, and are generated by the `goal_two.py`, `goal_three.py`, `goal_four.py` scripts. These scripts can be found inside the `src` directory.
- The `src` folder contains the python scripts created to solve exercises 1, 2, 3, 4 of this challenge and generate the expected results that are located inside the `output` directory.

# How does it work

**Get the code repository**: you can use the Github Desktop or the command below to clone the repository to your machine. 
After running this command, the repository will be cloned into a new directory named repository in your specified path.

```shell
git clone https://github.com/lserra/challenge_hippo.git
```

> After you get the code repository, you will notice that the project structure mentioned previously is missing a few folders. Don't worry, we can fix that!  

**Make the script executable**: open your terminal, navigate to the `challenge_hippo` directory (root), look for the shell script named `setup_project.sh` and run the command below.

```shell
chmod +x setup_project.sh
```

**Run the script**: execute the shell script to create the folders and set up the virtual environment.

```shell
./setup_project.sh
```

This script will:

- Create the analisys, database, input, and output folders.
- Create a virtual environment named `.venv`.
- Activate the virtual environment `.venv`.
- Install python packages.

**CSV/JSON files**: copy or move all folders and files uncompressed from `data.tar.gz` file to the `input` directory.

```text
├── input/
│ |  └── claims/
│ |     ├── output-2f620de6-8807-47bd-8034-13eec976c826.json
│ |  └── pharmacies/
│ |     ├── output-09482089-7f1b-4d36-a21f-4652ed460166.csv
│ |  └── reverts/
│ |     ├── output-1d5d70e3-d417-4fea-970d-95c04c64e0d5.json
```

**Get the results expected**: execute the python script below.

```shell
python3 hippo.py
```

After a few seconds you will see in your screen the results below:

```text
=====> pharmacies table created successfully
=====> claims table created successfully
=====> reverts table created successfully
/Users/lserra/PyProjects/challenge_hippo/src/goal_two.py:53: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
  df = pd.read_sql(query, con)
=====> bt_claims table created successfully
/Users/lserra/PyProjects/challenge_hippo/src/goal_two.py:81: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
  df = pd.read_sql(query, con)
=====> Metrics calculated successfully
=====> JSON file created successfully at /Users/lserra/PyProjects/challenge_hippo/output/metrics.json
/Users/lserra/PyProjects/challenge_hippo/src/goal_three.py:49: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
  df = pd.read_sql(query, con)
=====> Recommendations written to /Users/lserra/PyProjects/challenge_hippo/output/top_chains.json
/Users/lserra/PyProjects/challenge_hippo/src/goal_four.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
  df = pd.read_sql(query, con)
=====> Most common quantities written to /Users/lserra/PyProjects/challenge_hippo/output/most_common_quantities.json
✅ Hippo process finished successfully!
```

